# Model Configuration
clip:
  model_name: "openai/clip-vit-base-patch32"
  device: "cuda"  # or "cpu"
  batch_size: 32

# LLM Configuration
llm:
  provider: "openai"  # options: openai, groq
  model: "gpt-4o-mini"  # or llama3-70b-8192
  temperature: 0.7
  max_tokens: 200

# Stable Diffusion Configuration
stable_diffusion:
  model: "stabilityai/stable-diffusion-2-1"
  num_inference_steps: 50
  guidance_scale: 7.5
  height: 512
  width: 512

# Data Configuration
data:
  coco_subset_size: 10000
  image_size: 224
  val_split: 0.1

# FAISS Configuration
faiss:
  index_type: "IndexFlatIP"  # Inner Product (cosine similarity)
  normalize: true

# Retrieval Configuration
retrieval:
  top_k: 5
  similarity_threshold: 0.5

# Paths
paths:
  data_dir: "data/coco"
  processed_dir: "data/processed"
  embeddings_dir: "embeddings"
  experiments_dir: "experiments"
